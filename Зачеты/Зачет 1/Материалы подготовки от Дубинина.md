Традиционно для большинства языков использовались однобайтные кодировки: один знак кодировался одним байтом (японские, корейские и китайские, естественно, кодировались бо́льшим количеством байтов: двумя-тремя).

Т.к. один байт (8 бит, 0–255) может быть представлен в виде двух шестнадцатеричных цифр (0–F), например, A5 или 0A, то однобайтовые кодовые страницы традиционно изображают в виде таблиц 16x16, где по вертикали откладывают первую шестнадцатеричную цифру, по горизонтали — вторую, а на пересечении рисуют соответствующий знак. Например, 0A Будет в колонке 'A' нулевого ряда.

Кодировка ASCII, например, использует для кодирования только 7 бит. Старший всегда равен нулю, т.е. первая цифра шестнадцатеричного представления ASCII-кода будет находиться не в диапазоне 0-F, а в диапазоне 0-7, тогда таблицу можно условно разделить на две половины: первая половина таблицы (ряды 0–7), это байты с нулевым старшим битом, а вторая половина — со старшим битом равным 1. Это деление оказалось удобно в контексте ascii-совместимых кодировок: ascii занимает первую половину, а вторая свободна для варьирующихся от кодировки к кодировке региональных алфавитов и типографики, а также псевдографики.


Например, цифры и буквы в koi-8:

   .0 .1 .2 .3 .4 .5 .6 .7 .8 .9 .A .B .C .D .E .F
------------- эта часть равна ASCII --------------
0
1
2
3 0  1  2  3  4  5  6  7  8  9 
4    A  B  C  D  E  F  G  H  I  J  K  L  M  N  O 
5 P  Q  R  S  T  U  V  W  X  Y  Z  
6    a  b  c  d  e  f  g  h  i  j  k  l  m  n  o
7 p  q  r  s  t  u  v  w  x  y  z  
------------------- а эта нет --------------------
8.
9.
A.          ё
B.          Ё
C. ю  а  б  ц  д  е  ф  г  х  и  й  к  л  м  н  о
D. п  я  р  с  т  у  ж  в  ь  ы  з  ш  э  щ  ч  ъ
E. Ю  А  Б  Ц  Д  У  Ф  Г  Х  И  Й  К  Л  М  Н  О
F. П  Я  Р  С  Т  У  Ж  В  Ь  Ы  З  Ш  Э  Щ  Ч  Ъ


== ITA2 ==
International Telegraph Alphabet No.2
Докомпьютерная кодировка, использовавшаяся в телеграфной связи. Автоматизированные телеграфы было сложно спроектировать под код Морзе (он удобен человеку, но из-за пауз между буквами и переменной длины кодов — оказался плох для автоматических систем), поэтому использовался код фиксированной ширины, пять битов. Т.к. 32 значения явно маловато для представления даже только латинских букв и цифр, применялся приём переключения регистров: в одном регистре — коды для латинницы, в другом — цифры и пунткуация; два кода выделены для переключения регистров. В российской вариации кода (МТК-2) был ещё третий регистр — для русских букв.
Похожий приём потом нашёл применение в КОИ-7 для переключения Н0 и Н1.
Естественно, никакой речи не шло о раздельном представлении строчных и заглавных букв.


== EBCDIC ==
Extended Binary Coded Decimal Interchange Code — расширенный двоично-десятичный код обмена информацией.
Восьмибитная кодировка, основанная на шестибитной кодировке BCDIC.

В кодировке EBCDIC буквы и цифры располагаются так:

   .0 .1 .2 .3 .4 .5 .6 .7 .8 .9 .A .B .C .D .E .F
0    // В первой половине таблицы — служебные
…     // символы и, частично, пунктуация.
7    // Все буквы — во второй половине таблицы.
8  a  b  c  d  e  f  g  h  i
9     j  k  l  m  n  o  p  q  r
A.        s  t  u  v  w  x  y  z
B.
C.     A  B  C  D  E  F  G  H  I
D.     J  K  L  M  N  O  P  Q  R
E.        S  T  U  V  W  X  Y  Z
F.  0  1  2  3  4  5  6  7  8  9 

Это расположение перекочевало из шестибитной кодировки BCDIC с некоторыми изменениями.

В шестибитной кодировке BCDIC буквы и цифры располагались, например, так (вариант IBM 704):
   .0 .1 .2 .3 .4 .5 .6 .7 .8 .9 .A .B .C .D .E .F
0.  0  1  2  3  4  5  6  7  8  9 
1.     A  B  C  D  E  F  G  H  I
2.     J  K  L  M  N  O  P  Q  R
3.        S  T  U  V  W  X  Y  Z
Были варианты, где ноль кодировался как 0xA, но расположение букв и цифр 1–9 во всех вариантах совпадали

// Обратите внимание: таблица для шестибитной кодировки в четыре раза меньше, чем для восьмибитной (каждый дополнительный бит удваивает количество вариантов).

Такое кодирование букв в BCDIC берёт начало с перфокарт табулятора Холлерита, где каждая колонка состояла из двенадцати позиций: A,B,0-9. Знаки кодировались так:
- цифры — напрямую: отверстием в соответствующей позиции;
- буквы A-I — отверстие в позиции A плюс отверстие в одной из позиций 1-9
- буквы J-R — отверстие в позиции B плюс отверстие в одной из позиций 1-9
- буквы S-Z — отверстие в позиции 0 плюс отверстие в одной из позиций 2-9 (чтобы избежать соседства двух отверстий 0 и 1)
(см. статью https://habr.com/ru/post/521164/)
При переносе в компьютерное представление пометки A,B и 0 превратились в номер ряда в таблице: 0 — без пометок (цифры), 1 — пометка A (буквы A-I), 2 — пометка B (буквы J-R), 3 — пометка 0 (буквы S-Z).


В кодировке EBCDIC много свободных мест, но они не расположены так удобно, как в ASCII: создание национальных кодировок на основе EBCDIC — не так очевидно и не удобно, как на основе ASCII. Кроме того, сама EBCDIC тоже существует не в единственном виде: есть множество несовместимых между собой вариантов.


== ДКОИ (ДКОИ-8) ==
Двоичный код для обмена информацией.
8 бит, основана на EBCDIC (только добавлена кириллица), применялась в ЕС ЭВМ
Почти все буквы и цифры во второй половине таблицы. Букв ё,Ё,Ъ нет. Знаки кириллицы, похожие по начертанию на латинницу как правило не использовались, хотя в таблице присутствовали.


EBCDIC и, соответственно, ДКОИ, сейчас применяются разве что в системах, требующих совместимости с системами архаичными, ascii и ascii-совместимые кодировки в этом смысле оказались более живучими.





== ASCII ==
American Standard Code for Information Interchange.
Разработан изначально для телепринтеров, когда вследствие развития технологии появилась возможность заменить использовавшиеся тогда пятибитные телеграфные коды: https://en.wikipedia.org/wiki/Telegraph_code#ASCII
Для кодирования знака в ASCII используются 7 битов, т.е. при использовании в памяти компьютеров (где минимальная адресуемая единица информации — это восьмибитный байт), старший, восьмой бит всегда равен 0 (т.е. в табличном представлении кодировки — вторая половина таблицы пуста).
Сначала расположены управляющие символы, затем цифры и знаки препинания, потом заглавные буквы, потом строчные (только латинский алфавит).

Для упрощения устройства телетайпа буквы располагаются так, чтобы клавиша shift просто сбрасывала один бит (шестой), т.е., например, A=0x41,a=0x61, т.е. отличается только один бит. То же справедливо для всех букв и, например, цифр: цифра 1 отличается от знака !, а знаки <> от знаков ',' и '.' тем же самым шестым битом. Это до сих пор видно на раскладке QWERTY, где Shift+'1'='!', а Shift+','='<'. Однако есть и непривычные странности, например, круглые скобки с изменённым шестым битом станут не обычными для нас цифрами '9' и '0', а цифрами '8' и '9', но если поискать фотографии телетайпов тех времён, видно именно такую раскладку! А ещё в ascii цифра 2 соответствует знаку кавычки " при том, что на современной раскладке qwerty там @, а вот в кириллической раскладке йцукен сохранилось старое соответствие 2 и ".

В отличие от EBCDIC, основанной на совсем устаревшей идее перфокарт, ascii не содержала критического нагромождения legacy и оказалась удобна для использования в компьютерах, несмотря на то, что некоторые архитектурные решения были нацелены на применение в телетайпах. Просто эти решения оказались «не вредными» и не помешали распростронению ascii

На основе ASCII было создано множество национальных кодировок: для кириллицы, для европейских стран и т.д. (но не для стран с иероглифической письменностью: для их знаков места в одном байте никак не хватало).
Большинство ещё живых однобайтных кодировок совместимо с ASCII: в них знаки национальных алфавитов располагаются во второй половине таблицы (со старшим битом равным 1), т.е. ASCII, несмотря на свою древность, живее всех живых, хотя в чистом виде почти не встречается.


== КОИ-7 ==
Также семибитная, т.е. все русские буквы находятся в первой половине таблицы, т.е. она НЕ совместима с ascii.
Есть три варианта:
Н0 — английские буквы как в ascii, русских нет. Это вообще почти ASCII, только в старых версиях $ заменён на ¤
Н1 — есть русские буквы, но нет английских. Русские буквы стоят на месте похожих по звучанию английских
Н2 — есть английские заглавные и русские заглавные (занимают место английских строчных). При кодировании текста использовалась либо отдельно Н2, либо Н0 вместе с Н1 (с переключением между ними специальными кодами: 0xE на русский и 0xF на латинницу).


== KOI-8 ==
Совместима с ASCII, русские буквы стоят на местах, фонетически соответствующих аналогам из латинского алфавита: убрав 8й бит у кириллических букв получим читаемый в транслите текст (правда с перевёрнутым регистром, т.к. основана она на идеях КОИ-7, где заглавные русские буквы были вместо строчных латинских). 
Существует множество вариантов KOI8: koi8-R (русская), koi8-U (украинская) и т.д.
До недавнего времени была главной кодировкой в руссифицированных дистрибутивах linux, широко применялась в интернете на множестве web-сайтов.


== Основная кодировка ==
Совместима с ASCII, разработана в 1986 году в ВЦ Академии Наук СССР. Использовалась очень мало. Буквы ё и Ё уже в ней выпали из алфавитного порядка (имели коды больше, чем буква я).


== Альтернативная кодировка ==
Совместима с ASCII, основана на CP437 (DOSLatinUS, ASCII-совместимой кодировке с множеством европейских знаков). Европейские знаки заменены на кириллицу, псевдографика, присутствовавшая в CP437 оставлена на своих местах. Подходит для русского, белорусского и украинского алфавитов, за исключением Ґґ и кириллической Іі (использовали латинскую).
Существовало несколько вариантов альтернативной кодировки, но окончательным стандартом стала IBM CP866, поддержка которой была добавлена в MS-DOS. До недавнего времени командная строка Windows работала именно в этой кодировке (а может и сейчас работает :)


== ISO 8859-5 ==
Совместима с ASCII, основана на "основной" кодировке (переставлена заглавная Ё, добавлены І, и Ї, и некоторые другие знаки нерусской кириллицы, однако, Ґ нет).
Широко применяется в Сербии и Болгарии. В России распространения не получила (т.к. нет тире, кавычек-ёлочек, градуса и т.д.).
Часть стандарта ISO 8859 определяющего кодовые таблицы для разных алфавитов.
При проектировании Unicode порядок букв кириллицы был взят из этой кодировки, поэтому в юникоде «нелогичный» порядок букв, где Ё и ё находятся не в остальном алфавите.


== WINDOWS-1251 ==
Часть семейства кодировок window для кириллических письменностей (в этом же семействе есть, например, ещё windows-1252 — для западно европейских языков, и другие кодировки).
Совместима с ASCII, создана на основе ранних самодельных руссификаций windows в 1990-1991 годах.
Достоинства - есть почти все знаки русской типографики (кроме ударения), все знаки русского, украинского, белорусского, сербского и болгарского алфавитов.
Недостатки - нет псевдографики, буква "я" имеет код 255 (для однобайтного целого это значение неотличимо от -1 в дополнительном коде, а -1 часто использовалось как специальное значение, в т.ч. EOF, в разных программах, т.е. плохо написанные программы могли перепутать EOF и 'я')


== Многобайтные не-unicode кодировки ==
Разнообразные японские, китайские, корейские: где большие «алфавиты», не помещающиеся в 8 бит.


== UNICODE ==
Призван заменить весь этот зоопарк кодировок. Разрабатывался с 1991 года. Изначально полагали ограничиться созданием кодировки, где буква кодировалась бы двумя байтами, но на этой примитивной попытке рарвитие юникода не остановилось и теперь юникод — это не какая-то одна кодировка, а многогранный стандарт кодирования текста, включающий в себя не только набор знаков с номерами и именами (UCS, см. ниже), но и:
• правила сравнения знаков для алфавитной сортировки строк. Например, номер буквы Ё не соответствует её положению между Е и Ж, поэтому этот факт прописан отдельно
• правила нормализации (приведение к стандартной форме, например приведение к нижнему регистру, включая нетривиальные правила вроде ß → ss, удаление лишней диакритики для поиска по тексту, и т.д.)
• правила двунаправленного письма (вроде Арабского)
• соответствие модифицированных символов немодифицированным, например, букву ĥ из языка Эсперанто можно представить единственным code point'ом U+0125, а можно и двумя: буквой 'h' (U+0068) в сочетании с модификатором "крышка сверху" (U+02C6).
• и т.д.

Universal Character Set (UCS) ISO 10646 - основа юникода: набор знаков (т.е. таблица соответсвия числового кода знаку, имеющему название и графическое изображение). В UCS входит ~100 000 знаков.
Отдельный знак в таблице UCS называется code point'ом и обычно записывается как шестнадцатеричное число с префиксом U+, например: U+D022
Всё множество знаков делится на "плоскости" (17 штук по 65536 code point'ов).
BMP - Basic Multilingual Plane - первые 65536 знаков, включающие наиболее часто используемые знаки и до 2000 года в основном использовалась только эта часть юникода. Однако в 2000м году, КНР постановила, что все компьютеры, поставляемые туда должны поддерживать набор знаков GB18030 (часть из которых оказалась за пределами первой плоскости юникода, это дало стимул к интеграции более полной поддержки юникода в программные продукты).

На основе UCS сделано множество кодировок, которые делятся на два типа:
• UCS - прямая запись кодпойнта целым числом. UCS-4: каждая буква — четырёхбайтное целое, код из UCS. UCS-2 — аналогично, но всего 2 байта, т.е. множество кодируемых букв ограничивается плоскостью BMP
• UTF - кодировки, в которых для получения code point'а (кода буквы), надо сделать какие-то преобразования

Два важных термина:
- code point — численный код знака, представленный в кодировке (в частности, в UCS). В случае юникода code point обычно записывается в шестнадцатеричном виде с префиксом U+, например U+02C6;
- code unit (кодовая единица) — атомарный элемент конкретной кодировки. Например, в UTF-16 это двухбайтовое целое, в UTF-32 — четырёхбайтовое целое, а в UTF-8 — просто один байт.
В однобайтовых кодировках не было смысла разделять эти два понятия, т.к. по сути один code unit соответствовал одному code point и не требовалось дополнительных операций. В UTF-кодировках же code point может кодироваться одним или несколькими code unit'ами (например, один code point в UTF_16 кодируется одним или двумя code unit'ами: двухбайтовыми целыми, а в UTF-8: одним, двумя, тремя или четырьмя байтами). 


== UTF-16 ==

UTF-16 - Часть знаков кодируется как в UCS-2, остальные - более сложно, парами. В диапазоне UCS-2 есть неиспользуемое пространоство U+D800..U+DFFF, которое разбили на две равные части (High Surrogates: U+D800..U+DBFF и Low Surrogates: U+DC00..U+DFFF). Для кодирования знаков, не влезших в UCS-2. используется сочетание из двух значений: одно из High Surrogates, второе — из Low Surrogates Т.е. UTF-16 имеет переменную длину знаков (одно двухбайтное целое либо 2 двухбайтных целых)

Принцип кодирования:
1. Если значение code point'а меньше 0x10000, то он кодируется как есть, двухбайтным целым;
2. Иначе code point кодируется двумя code unit'ами, high surrogate и low surrogate:
  (C - 0x10000) >> 10 + 0xD800 — это high surrogate (HS) // сдвинули вправо с потерей младших 10 битов
  (С - 0x10000) & 0b1111111111 + 0xDC00 — это low surrogate (LS) // оставили только младшие 10 битов
  // заметим, что 0b1111111111 = ((1 << 10) - 1). А ещё удобнее использовать hex-вид: 0x3FF
  
Для декодирования суррогатной пары нужно выполнить обратные действия:
  ((HS - 0xD800) << 10) + (LS - 0xDC00) + 0x10000
  
Слегка модифицированный пример кодирования из википедии:
Закодируем смайлик U+1F606 (😆) в UTF-16:
  Вычитаем 0x10000: 0x1F606 - 0x10000 = 0xF606
  Для вычисления high surrogate, сдвигаем вправо на 10 (делим на 0x400), затем прибавляем 0xD800:
  (0xF606 >> 10) + 0xD800 = 0x3D + 0xD800 = 0xD83D
  Для вычисления low surrogate, оставляем только младшие 10 битов, затем прибавляем 0xDC00:
  (0xF606 & 0x3FF) + 0xDC00 = 0x206 + 0xDC00 = 0xDE06
Т.е. этот смайлик будет закодирован как два двухбайтовых целых: 0xD83D 0xDE06

Теперь декодируем его обратно. Если в тексте мы встретим число из множества high surrogate'ов, то за ним обязательно должно следовать число из множества low surrogate'ов. Извлекаем их оба.

В нашем примере это два двухбайтовых целых Hight Surrogate = 0xD83D и Low Surrogate = 0xDE06
  Из верхнего суррогата получаем: 0xD83D - 0xD800 = 0x3D, сдвигаем влево на 10 битов: 0xF400
  Из нижнего суррогата: 0xDE06 - 0xDC00 = 0x206
  0xF400 + 0x206 + 0x10000 = 0x1F606 — это исходное значение code point'а смайлика 😆


== UNICODE BOM, проблема порядка байт ==
Для кодировок, использующих целые длиной больше одного байта (UCS-* и UTF-16) характерна проблема порядка байт, Byte Order, Endianness. Дело в том, что разные архитектуры размещают байты в памяти в разном порядке: от старшего к младшим (Big Endian, BE) или от младшего к старшему (Little Endian, LE). При обмене данными между такими системами может возникнуть непонимание.

Поэтому применяется специальная Byte Order Mark - метка порядка байтов.
Метка представляет собой знак неразрывного пробела нулевой ширины. Есть такой в юникоде, имеет код U+FEFF, при этом кода U+FFFE не существует, так что если в начале текста присутствует BOM, можно однозначно определить, какой порядок байт в unicode-последовательностях в этом тексте.
BOM'ы выглядят так:
UTF-16: FE FF (BE) или FF FE (LE)
UTF-32: 00 00 FE FF (BE) или FF FE 00 00 (LE)

Открывая блокнотом windows текст в кодировке UTF-16, можно столкнуться с тем, что файл будет виден как два или три знака, первые два из которых "яю" или "юя". Вот это как раз и есть попытка блокнота показать юникодный BOM как текст в кодировке cp1251. Дальнейший текст обрубается, т.к. блокнот воспринимает нулевой байт как конец текста, а в UTF-16 нулевой байт будет присутствовать уже в первой букве почти с гарантией.


Ещё одной попыткой решить проблему порядка байт было кодирование codepoint'ов потоком байтов, один за другим, а не многобайтными целыми. Так родилась кодировка UTF-1, но и она имела проблемы (см. дальше), кроме того, ещё и медленная была: для получения кодпойнта приходилось использовать деление, а это небыстрая операция).


== Прочие проблемы ==
Поимимо этого, многие кодировки юникода имеют следующие проблемы:
• нулевые байты в тексте. Си-программы не могут прочитать строку в этих кодировках, т.к. считают нулевой байт за окончание строки
• потеря байта ломает не одну букву, а весь текст после (трудно понять, где кончается сбойная буква и пора начать читать следующую)
• несовместимость с ASCII
• нигде (даже в UCS-*) никак нельзя выяснить длину текста в буквах, зная только длину текста в байтах (а это даже в ascii не работало в полной мере из-за BS+_): в юникоде одинаково выглядящий текст можно закодировать совершенно разными способами, например одна буква Ĥ может быть закодирована как один code-point, а может — как два: H и ^-над-буквой, т.е. не разбирая текст, просто зная длину текста в code-point'ах, нельзя понять длину текста в буквах.

С последней проблемой сделать ничего нельзя, решением остальных проблем стала UTF-8, разработанная Дейвом Поссером, Кеном Томпсоном и Робом Пайком для операционной системы Plan9. Сейчас эта кодировка — фактический стандарт для web'а и не только.


== UTF-8 ==

Знаки из ASCII кодируются один-в-один одним байтом, старший бит, естественно, 0:
0xxxxxxx — знаки из ASCII
Остальные code point'ы кодируются несколькими байтами (code unit'ами), первый из которых дополнительно кодирует длину:
110xxxxx — всего будет два code-unit'а (байта), плюс в первом байте 5 битов полезной нагрузки
1110xxxx — всего будет три байта, в первом байте 4 бита полезной нагрузки
и т.д.: сколько единиц в начале — столько байтов и будет использовано для кодирования
А второй и последующие байты выглядят так:
10xxxxxx — шесть битов полезной нагрузки

Таким образом:
- двумя байтами (5+6 = 11 битов полезной нагрузки) в UTF-8 можно закодировать 2^(5+6) = 2^11 = 2048 знаков (кириллица, например, кодируется двумя байтами)
- тремя байтами (4+6+6 = 16 битов полезной нагрузки) можно закодировать 2^(4+6+6) = 2^16 = 65536 знаков, т.е. всю BMP. 
- четыре байта (3+6+6+6 = 21 бит полезной нагрузки) покрывают всё протранство unicode'а.

При кодировании надо выбирать минимальное количество байтов. Т.е., например, нельзя просто приписать слева нулей и использовать трёхбайтовое представление там, где достаточно двухбайтового.

Достоинства:
• совместима с ASCII
• нулевых байтов внутри текста нет, кроме ASCII'шного нулевого байта
• порядок байтов в целых числах не важен, т.к. для кодирования используются последовательности байтов, а не многобайтные числа
• после потери/искажения байта легко найти начало следующей буквы (байты, кодирующие начало и продолжение буквы разительно отличаются)
• быстрая! Все операции для раскодирования — битовые сдвиги и маски.

Очевидно, что BOM не нужен, но неразрывный пробел нулевой ширины всё-таки существует :) Вот так он будет выглядеть в UTF-8: три байта EF BB BF

Пример
Закодируем тот же смайлик U+1F606 (😆).

В двоичном виде это будет 0x1F606 = 0b11111011000000110 — 17 двоичных разрядов. В 16 битов полезной нагрузки для трёх байтов мы не влезаем, так что придётся использовать четыре байта: 3+6+6+6 битов:

000|011111|011000|000110

Первый байт кодирует количество code unit'ов (4) и содержит три бита полезной нагрузки (000): 11110000
Второй и последующие начинаются с 10 и содержат по шесть битов полезной нагрузки: 10011111, 10011000, 10000110.
Т.е. весь смайлик будет закодирован четырьмя байтами: 11110000, 10011111, 10011000, 10000110.
Или, в шестнадцатеричном виде: 0xf0 0x9f 0x98 0x86


Теперь декодируем его же. Читая байт-за-байтом исходный текст в utf-8, мы натыкаемся на байт 0xf0 (или в двоичном виде 11110000). Это начальнй байт четырёхбайтового кода (т.к. начинается на 11110), значит нужно дочитать ещё три байта. Дочитываем их: 10011111, 10011000, 10000110 и проверяем, что все они являются байтами-продолжениями, т.е. начинаются на биты 10. Теперь просто очищаем от служебных битов и склеиваем:

11110000 10011111 10011000 10000110
_____000 __011111 __011000 __000110
000|011111|011000|000110
0b11111011000000110 = 0x1F606 — это исходное значение code point'а смайлика 😆



== Экзотика, UTF-7 ==

UTF-7 - также многобайтна. Кодирование всех знаков только с помощью ASCII. Не влезающие в ASCII знаки кодируются как "+код-" ("+" кодируется как "+-")
Используется для записи заголовков email (там ничего кроме ASCII нельзя использовать). Экономичней, чем пара UTF-8 + Quoted Printable (другой способ записи с помощью ASCII знаков за пределами ASCII).
## Взаимосвязи рассмотренных кодировок 

Для наглядности, кратко перечислим рассмотренные выше кодировки, отмечая их родословную

### Иерархия кодировок на основе BCDIC (все мертвы)

Перфокарты
- BCDIC (шестибитная)
	- EBCDIC (восьмбитная)
		- ДКОИ-8 (одна из множества основанных на EBCDIC, восьмибитная, кириллическая)


### Иерархия кодировок на основе ASCII (многие кодировки до сих пор живы, хотя и вытесняются юникодом) 

ASCII (1964г, семибитная. Разработана с нуля для телепринтеров)
- КОИ-7 (1967г, семибитная, не совместимая с ASCII, хотя и сделана на её основе. Единая в трёх ипостасях: Н0, Н1, Н2)
- - КОИ-8 (1974г, восьмибитная, совместимая с ASCII. Несколько версий, включая koi8-r, koi8-u, koi8-ru)
- CP437 (DOSLatinUS: для латинницы и её европейских вариаций, стандарт латинницы и псевдографики для MS DOS)
- - Альтернативная кодировка (1986г, ВЦ Академии Наук СССР, псеводграфика на тех же позициях, что и в CP437)
- - - CP866 (1990г, версия альтернативной кодировки, ставшая окончательным стандартом кириллицы для MS DOS)
- Основная кодировка (1986г, ВЦ Академии Наук СССР, псевдографика есть, но не там же, где в CP437, поэтому не прижилась)
- - ISO 8859-5 (1988г, ISO и IEK на базе основной, кириллическая часть стандарта ISO 8859, псевдографики нет)
- Windows-1251 (199Xг Microsoft, на основе любительских локализаций Windows, часть семейства кодировок Windows)


= Unicode =

UCS (база юникода): за основу взято множество существовавших кодировок, включая:
- ISO 8859-1: первые 256 code point'ов UCS совпадают с ISO 8859-1 (расширенная латинница)
- ISO 8859-5: буквы кириллицы расположены в том же порядке

На UCS основаны все юникодовые кодировки: UCS-2, UTF-16, UTF-8 и т.д.


